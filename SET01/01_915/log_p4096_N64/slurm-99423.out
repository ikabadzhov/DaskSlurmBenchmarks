Auks API request failed : krb5 cred : unable to read credential cache
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:38561'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:44977'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:33327'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:35523'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:33765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:35007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:45177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:32887'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:34283'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:39657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:36543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:43473'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:39877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:35773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:45821'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:34813'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:35365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:34587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:45203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:37141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:44263'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:44533'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:46253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:33281'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:35421'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:33501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:36841'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:43177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:35565'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:35989'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:42855'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.42:44723'
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:41555
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:38489
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:32943
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:41555
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:38489
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:32943
distributed.worker - INFO -          dashboard at:           10.32.2.42:39661
distributed.worker - INFO -          dashboard at:           10.32.2.42:36517
distributed.worker - INFO -          dashboard at:           10.32.2.42:44433
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:42565
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:37823
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:42565
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:39153
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:39757
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:37823
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:40277
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:42451
distributed.worker - INFO -          dashboard at:           10.32.2.42:43477
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:40709
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:35887
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:39153
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:39757
distributed.worker - INFO -          dashboard at:           10.32.2.42:37279
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:40277
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:38375
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:42451
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:36921
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:40709
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:35887
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.42:41871
distributed.worker - INFO -          dashboard at:           10.32.2.42:36659
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-idl47lpv
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-5a7zanb6
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:39889
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:33013
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:33781
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:38375
distributed.worker - INFO -          dashboard at:           10.32.2.42:32789
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:36529
distributed.worker - INFO -          dashboard at:           10.32.2.42:44679
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-o_el7w5o
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:36921
distributed.worker - INFO -          dashboard at:           10.32.2.42:33751
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:44159
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:37469
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:39889
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:33013
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          dashboard at:           10.32.2.42:38137
distributed.worker - INFO -          dashboard at:           10.32.2.42:34337
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:36529
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:45719
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:39651
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:44159
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:37469
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:44631
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:40089
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:41569
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:41415
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:39231
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:39043
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:39651
distributed.worker - INFO -          dashboard at:           10.32.2.42:35967
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-43itb0ck
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.42:37595
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          dashboard at:           10.32.2.42:32963
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:40089
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:43649
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:41569
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:41415
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:39043
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-3854t9ru
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:36971
distributed.worker - INFO -          dashboard at:           10.32.2.42:39299
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:43649
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:37293
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-dtqbdggc
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-nm3eyodq
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-83vpwx8e
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-slw9vfas
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:46525
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:44985
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-9766v5tf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:36971
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:           10.32.2.42:45537
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ytvz7s36
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-lwwn5hnz
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:39509
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-5rpo4rwm
distributed.worker - INFO -          dashboard at:           10.32.2.42:40305
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-bragj7pc
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:39509
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-aks0_vmp
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-tcs4fxn3
distributed.worker - INFO -          dashboard at:           10.32.2.42:43277
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-knxw6a3_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-di9_zdwu
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-4dmc2prn
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-su_4d2g0
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_w1gcchc
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-s5erg760
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-dgoeu_f3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vk6fcram
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_yoqud_e
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-qqz1fmys
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:44235
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:42299
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:44235
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:42299
distributed.worker - INFO -          dashboard at:           10.32.2.42:39367
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:39397
distributed.worker - INFO -          dashboard at:           10.32.2.42:46727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:39397
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:35039
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:33183
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-jit2d5p7
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:33183
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.42:40501
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-9prcb_op
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:44837
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-8qalvgm6
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:44837
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.42:43541
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.42:39119
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          Listening to:     tcp://10.32.2.42:43541
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-w818dkqm
distributed.worker - INFO -          dashboard at:           10.32.2.42:40515
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-2ptl9ds7
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-s_xlmxe7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.371229 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f537.root}: entry range [0,61540412], using slot 0 in thread 140197220407040.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.382685 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f553.root}: entry range [0,61540412], using slot 0 in thread 140404438488832.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.410477 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f555.root}: entry range [0,61540412], using slot 0 in thread 140701956433664.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.91s CPU, 8.95347s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.87s CPU, 9.04352s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.54s CPU, 10.0572s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.883696 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f503.root}: entry range [0,61540412], using slot 0 in thread 140197220407040.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.888299 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f480.root}: entry range [0,61540412], using slot 0 in thread 140701956433664.
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:38561'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:44977'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:35523'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:44235
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:33765'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:36921
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:45177'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:42451
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:35007'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:37469
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:32887'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:40277
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:34283'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:44159
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:39657'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:38375
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:36543'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:39509
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:39877'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:35773'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:41555
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:39757
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:45821'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:40089
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:34587'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:33013
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:34813'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:35365'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:43541
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:45203'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:42565
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:44263'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:33183
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:44533'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:39397
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:32943
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:37141'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:36971
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:33281'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:39153
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:46253'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:40709
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:41569
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:33501'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:35421'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:43649
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:39043
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:36841'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:35565'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:38489
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:43177'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:44837
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:35989'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:36529
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:39651
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:41415
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.42:44723'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.42:37823
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 335, in start
    response = await self.instantiate()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 404, in instantiate
    result = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 273, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1128, in __call__
    return self.main(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1053, in main
    rv = self.invoke(ctx)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 754, in invoke
    return __callback(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 691, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 277, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324300 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324298 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324295 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324291 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324289 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324286 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324282 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324278 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324276 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324274 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324270 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324266 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324260 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324258 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324254 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324251 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324247 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324241 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324237 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324222 parent=324165 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=324210 parent=324165 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    assert exitcode is not None
AssertionError
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
