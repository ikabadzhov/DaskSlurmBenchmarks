Auks API request failed : krb5 cred : unable to read credential cache
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:33035'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:38919'
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-l06rt28v', purging
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-da8v8i_0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-fw3jv8mo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-v4k3ugdc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-xl4iqmgu', purging
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:45133
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:45133
distributed.worker - INFO -          dashboard at:           10.32.2.38:43651
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:43983
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:43983
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-dl0q3grh
distributed.worker - INFO -          dashboard at:           10.32.2.38:40377
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-fcoykugh
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:43139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:46359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:35007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:39469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:36053'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:36723'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:42691'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:37331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:35081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:45031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:35099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:33881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:39673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:41449'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:41923'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:38789'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:33207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:34391'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:44605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:36057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:33953'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:35287'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:40899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:45253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:42057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:42421'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:37105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:39009'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:40025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.38:36089'
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:34819
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:34819
distributed.worker - INFO -          dashboard at:           10.32.2.38:43949
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-qu9s0lc0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:43289
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:43289
distributed.worker - INFO -          dashboard at:           10.32.2.38:42903
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-5ht3bepg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:35585
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:35585
distributed.worker - INFO -          dashboard at:           10.32.2.38:33103
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-i365kl68
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:36819
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:36819
distributed.worker - INFO -          dashboard at:           10.32.2.38:39715
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-pom0pism
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:46725
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:46725
distributed.worker - INFO -          dashboard at:           10.32.2.38:46501
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-bc2bijgb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:40665
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:40665
distributed.worker - INFO -          dashboard at:           10.32.2.38:34125
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-6b30antx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:43361
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:43361
distributed.worker - INFO -          dashboard at:           10.32.2.38:38601
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-dmvcdhs7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:40817
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:40817
distributed.worker - INFO -          dashboard at:           10.32.2.38:41069
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-lw9ll7_y
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:33213
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:33213
distributed.worker - INFO -          dashboard at:           10.32.2.38:34283
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-k9gproh4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:36109
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:36109
distributed.worker - INFO -          dashboard at:           10.32.2.38:45353
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-wp1g_j77
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:43707
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:43707
distributed.worker - INFO -          dashboard at:           10.32.2.38:39243
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-h2kldd28
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:43293
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:43293
distributed.worker - INFO -          dashboard at:           10.32.2.38:41829
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-zep1o8no
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:43365
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:43365
distributed.worker - INFO -          dashboard at:           10.32.2.38:40521
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-82ub5pva
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:40889
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:40889
distributed.worker - INFO -          dashboard at:           10.32.2.38:37561
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-4tat8cwt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:32813
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:32813
distributed.worker - INFO -          dashboard at:           10.32.2.38:35841
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vevpqfho
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:38609
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:38609
distributed.worker - INFO -          dashboard at:           10.32.2.38:45301
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ti62n3ka
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:44615
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:44615
distributed.worker - INFO -          dashboard at:           10.32.2.38:40015
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-446_pnuy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:46457
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:46457
distributed.worker - INFO -          dashboard at:           10.32.2.38:39387
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-mah45n7w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:33829
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:33829
distributed.worker - INFO -          dashboard at:           10.32.2.38:40529
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vvfojqvj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:33041
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:33041
distributed.worker - INFO -          dashboard at:           10.32.2.38:46411
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-7kh6_cjp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:34599
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:34599
distributed.worker - INFO -          dashboard at:           10.32.2.38:36731
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-y6el9b9n
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:42895
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:42895
distributed.worker - INFO -          dashboard at:           10.32.2.38:46199
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-auxjixij
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:42261
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:42261
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:43047
distributed.worker - INFO -          dashboard at:           10.32.2.38:40283
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:43047
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.38:37247
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-blkvxufh
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-a5kcpmhn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:39183
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:39183
distributed.worker - INFO -          dashboard at:           10.32.2.38:40955
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-y02u4gz5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:41639
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:36253
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:36253
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:41639
distributed.worker - INFO -          dashboard at:           10.32.2.38:37961
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.38:38597
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-wccw837o
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-1bauyqya
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:37759
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:37759
distributed.worker - INFO -          dashboard at:           10.32.2.38:33985
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-e9avtiv6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:36193
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:36193
distributed.worker - INFO -          dashboard at:           10.32.2.38:41029
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-s2j5_akm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.38:42201
distributed.worker - INFO -          Listening to:     tcp://10.32.2.38:42201
distributed.worker - INFO -          dashboard at:           10.32.2.38:37477
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-zfpe_1wf
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.361754 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f215.root,input_files/dimuon/f216.root}: entry range [0,123080825], using slot 0 in thread 139779394995968.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.408032 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f217.root}: entry range [0,61540412], using slot 0 in thread 140028842571520.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.419976 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f206.root}: entry range [0,61540412], using slot 0 in thread 139780753299200.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.420052 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f207.root}: entry range [0,61540412], using slot 0 in thread 140178050414336.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.82s CPU, 9.54225s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.99s CPU, 9.78876s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.49s CPU, 9.96898s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.4s CPU, 9.99568s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.894931 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f217.root}: entry range [0,61540412], using slot 0 in thread 140028842571520.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.887438 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f206.root}: entry range [0,61540412], using slot 0 in thread 139780753299200.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.876463 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f216.root}: entry range [0,61540412], using slot 0 in thread 139779394995968.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.882964 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f206.root,input_files/dimuon/f207.root}: entry range [0,123080825], using slot 0 in thread 140178050414336.
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f2124f3ccd0>>, <Task finished name='Task-11' coro=<Worker.heartbeat() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:992> exception=OSError('Timed out during handshake while connecting to tcp://188.185.68.194:42727 after 30 s')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 198, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 318, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1041, in heartbeat
    raise e
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1001, in heartbeat
    response = await retry_operation(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 385, in retry_operation
    return await retry(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 370, in retry
    return await coro()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1059, in connect
    raise exc
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 323, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://188.185.68.194:42727 after 30 s
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.99s CPU, 8.88086s elapsed).
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.78s CPU, 8.66284s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.86s CPU, 8.74753s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.02s CPU, 8.95183s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.354412 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f246.root}: entry range [0,61540412], using slot 0 in thread 140494810363648.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.896835 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f217.root}: entry range [0,61540412], using slot 0 in thread 140028842571520.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.882044 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f244.root,input_files/dimuon/f245.root}: entry range [0,123080825], using slot 0 in thread 139779394995968.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.895215 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f216.root,input_files/dimuon/f217.root}: entry range [0,123080825], using slot 0 in thread 139780753299200.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.886101 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f206.root}: entry range [0,61540412], using slot 0 in thread 140178050414336.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.440467 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f325.root,input_files/dimuon/f326.root}: entry range [0,123080825], using slot 0 in thread 140554729076480.
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.36s CPU, 9.48839s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.19s CPU, 9.49665s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.59s CPU, 10.0804s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.75s CPU, 9.88871s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.7s CPU, 9.65549s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.883086 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f216.root}: entry range [0,61540412], using slot 0 in thread 139779394995968.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.356911 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f468.root}: entry range [0,61540412], using slot 0 in thread 140690956642048.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.391991 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.894226 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f759.root}: entry range [0,61540412], using slot 0 in thread 139780753299200.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f690.root}: entry range [0,61540412], using slot 0 in thread 139823940847360.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.904112 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f595.root}: entry range [0,61540412], using slot 0 in thread 140028842571520.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.885976 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f82.root}: entry range [0,61540412], using slot 0 in thread 140494810363648.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.893367 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f438.root}: entry range [0,61540412], using slot 0 in thread 140178050414336.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.52s CPU, 9.44588s elapsed).
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:41923'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:44605'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:39469'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:46359'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:43707
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:36253
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:33953'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:33213
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:35287'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:38789'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:40665
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:39183
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:34391'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:44615
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:40899'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:36089'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:42201
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:35585
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:39009'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:33829
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:45031'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:45253'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:43047
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:42261
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:41449'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:46457
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:38609
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:33881'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:33207'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:42895
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:40025'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:34599
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:42421'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:33041
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:36053'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:40889
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:42057'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:37759
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:41639
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:32813
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:36723'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:35099'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:35007'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.38:35081'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:36109
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:43293
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:46725
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.38:43365
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 335, in start
    response = await self.instantiate()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 404, in instantiate
    result = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 273, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1128, in __call__
    return self.main(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1053, in main
    rv = self.invoke(ctx)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 754, in invoke
    return __callback(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 691, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 277, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323398 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323393 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323389 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323377 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323368 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323355 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323352 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323349 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323344 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323340 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323338 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323334 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323325 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323319 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323243 parent=323199 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=323240 parent=323199 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    assert exitcode is not None
AssertionError
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
    assert exitcode is not None
Traceback (most recent call last):
AssertionError
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
