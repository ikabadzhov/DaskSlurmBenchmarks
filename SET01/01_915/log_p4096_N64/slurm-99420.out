Auks API request failed : krb5 cred : unable to read credential cache
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:41851'
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:36357
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:36357
distributed.worker - INFO -          dashboard at:           10.32.2.17:41855
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-4kw9vspz
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:42285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:35217'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:45067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:33949'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:36995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:34865'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:35673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:45745'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:37121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:43365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:46345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:45729'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:40929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:43067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:40369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:43517'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:45555'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:35839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:36999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:33351'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:41215'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:40323'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:38679'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:46873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:44105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:34289'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:39297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:46135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:36409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:43439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.17:38177'
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:40085
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:40085
distributed.worker - INFO -          dashboard at:           10.32.2.17:33523
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-l3t2y03j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:40889
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:40889
distributed.worker - INFO -          dashboard at:           10.32.2.17:42551
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-uasxbxbd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:43443
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:43443
distributed.worker - INFO -          dashboard at:           10.32.2.17:43257
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-c0qkk3ky
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:38443
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:38443
distributed.worker - INFO -          dashboard at:           10.32.2.17:38511
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-aykg7lih
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:33107
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:33107
distributed.worker - INFO -          dashboard at:           10.32.2.17:38303
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-6nb5pxz6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:44309
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:44309
distributed.worker - INFO -          dashboard at:           10.32.2.17:37265
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-sooyao_5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:46567
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:42017
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:46567
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:42017
distributed.worker - INFO -          dashboard at:           10.32.2.17:40201
distributed.worker - INFO -          dashboard at:           10.32.2.17:44089
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-qwq5l8ed
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-sc5xnqi_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:34147
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:34147
distributed.worker - INFO -          dashboard at:           10.32.2.17:35597
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-olw7w403
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:46321
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:46321
distributed.worker - INFO -          dashboard at:           10.32.2.17:42019
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-5435t1h1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:35831
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:35831
distributed.worker - INFO -          dashboard at:           10.32.2.17:36885
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-abe_vmek
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:36133
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:36133
distributed.worker - INFO -          dashboard at:           10.32.2.17:42883
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:45019
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:45019
distributed.worker - INFO -          dashboard at:           10.32.2.17:44079
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-bxkl2fys
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-kxi9gbr4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:37819
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:37819
distributed.worker - INFO -          dashboard at:           10.32.2.17:43339
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-uq0ci5b0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:42209
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:42209
distributed.worker - INFO -          dashboard at:           10.32.2.17:38457
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-oopppx1t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:37085
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:43401
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:43401
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:37085
distributed.worker - INFO -          dashboard at:           10.32.2.17:46325
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.17:38819
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-k51oxe3e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:39609
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:39609
distributed.worker - INFO -          dashboard at:           10.32.2.17:45007
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-7gvntfz_
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-erdmzpla
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:38725
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:38725
distributed.worker - INFO -          dashboard at:           10.32.2.17:43523
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-h2i54dfk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:39741
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:39741
distributed.worker - INFO -          dashboard at:           10.32.2.17:38781
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-xr057grf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:44745
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:44745
distributed.worker - INFO -          dashboard at:           10.32.2.17:33747
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-syphr0dx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:35861
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:35861
distributed.worker - INFO -          dashboard at:           10.32.2.17:37937
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-2nxqb98n
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:45115
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:45115
distributed.worker - INFO -          dashboard at:           10.32.2.17:34175
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-wjepj678
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:32795
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:32795
distributed.worker - INFO -          dashboard at:           10.32.2.17:35013
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-uxa4pbf8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:36887
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:36887
distributed.worker - INFO -          dashboard at:           10.32.2.17:40471
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-hwzk7qam
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:38365
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:38365
distributed.worker - INFO -          dashboard at:           10.32.2.17:40773
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:45797
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:45797
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vozyk0m4
distributed.worker - INFO -          dashboard at:           10.32.2.17:40683
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-2mqrw6nv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:45143
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:45143
distributed.worker - INFO -          dashboard at:           10.32.2.17:42283
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-cjrkdpu9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:39157
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:39157
distributed.worker - INFO -          dashboard at:           10.32.2.17:39213
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-8qoq9885
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:35637
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:35637
distributed.worker - INFO -          dashboard at:           10.32.2.17:39727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ijlxlkfh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.17:37213
distributed.worker - INFO -          Listening to:     tcp://10.32.2.17:37213
distributed.worker - INFO -          dashboard at:           10.32.2.17:43979
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-jgtzs15m
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.425446 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f403.root,input_files/dimuon/f404.root}: entry range [0,123080825], using slot 0 in thread 140288403564288.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.460546 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f323.root}: entry range [0,61540412], using slot 0 in thread 139858119386880.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.427627 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f403.root}: entry range [0,61540412], using slot 0 in thread 140115430557440.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.18s CPU, 9.77222s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.22s CPU, 9.77543s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.5s CPU, 10.2841s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.894656 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f404.root}: entry range [0,61540412], using slot 0 in thread 140115430557440.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.901153 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f439.root}: entry range [0,61540412], using slot 0 in thread 139858119386880.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.894161 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f404.root}: entry range [0,61540412], using slot 0 in thread 140288403564288.
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f6f11456cd0>>, <Task finished name='Task-11' coro=<Worker.heartbeat() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:992> exception=OSError('Timed out during handshake while connecting to tcp://188.185.68.194:42727 after 30 s')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 198, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 318, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1041, in heartbeat
    raise e
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1001, in heartbeat
    response = await retry_operation(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 385, in retry_operation
    return await retry(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 370, in retry
    return await coro()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1059, in connect
    raise exc
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 323, in connect
    raise OSError(
OSError: Timed out during handshake while connecting to tcp://188.185.68.194:42727 after 30 s
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:40889
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.1s CPU, 9.29518s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.14s CPU, 9.26167s elapsed).
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.81s CPU, 9.11946s elapsed).
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:40369'
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.891323 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f404.root}: entry range [0,61540412], using slot 0 in thread 140115430557440.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.889862 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f403.root}: entry range [0,61540412], using slot 0 in thread 140288403564288.
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.93s CPU, 8.79622s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.76s CPU, 9.61512s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.442459 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f661.root}: entry range [0,61540412], using slot 0 in thread 139875491645184.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.895381 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f619.root}: entry range [0,61540412], using slot 0 in thread 140288403564288.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.434702 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f569.root,input_files/dimuon/f570.root}: entry range [0,123080825], using slot 0 in thread 140203345733376.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.500069 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f706.root}: entry range [0,61540412], using slot 0 in thread 139922652051200.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 0.914322 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events,Events} in files {input_files/dimuon/f621.root,input_files/dimuon/f622.root}: entry range [0,123080825], using slot 0 in thread 140115430557440.
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:36995'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:42285'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:34865'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:44309
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:46345'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:43443
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:33949'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:38443
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:38679'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:45797
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:35673'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:45067'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:43401
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:35831
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:45729'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:45555'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:39609
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:45019
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:43067'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:36887
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:43365'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:45143
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:45745'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:38725
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:36999'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:40929'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:39157
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:33351'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:46567
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:44745
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:40323'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:37085
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:43517'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:42209
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:46873'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:38365
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:41215'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:35839'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:37213
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:33107
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:46135'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:34289'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:36133
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:35637
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:36409'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:43439'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:35861
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:39741
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.17:39297'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:46321
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:42017
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.17:45115
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 416709 was killed by signal 15
distributed.nanny - INFO - Worker process 416776 was killed by signal 15
distributed.nanny - INFO - Worker process 416728 was killed by signal 15
distributed.nanny - INFO - Worker process 416732 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 335, in start
    response = await self.instantiate()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 404, in instantiate
    result = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 273, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1128, in __call__
    return self.main(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1053, in main
    rv = self.invoke(ctx)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 754, in invoke
    return __callback(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 691, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 277, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=416800 parent=416631 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=416783 parent=416631 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=416734 parent=416631 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=416713 parent=416631 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=416670 parent=416631 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
