Auks API request failed : krb5 cred : unable to read credential cache
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:36747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:36421'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:41681'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:36385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:43015'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:40333'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:39367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:36345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:39419'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:34655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:39765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:34101'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:39969'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:34735'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:33109'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:38765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:43359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:39457'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:41927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:45917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:45479'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:42093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:40989'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:34475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:40681'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:37769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:46727'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:44689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:35577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:46711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:46523'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.36:32871'
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-78xu_9xf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-ioooa4vk', purging
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:44677
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:44677
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:35299
distributed.worker - INFO -          dashboard at:           10.32.2.36:44567
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:43361
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:45951
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:35299
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:43361
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:45951
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:43029
distributed.worker - INFO -          dashboard at:           10.32.2.36:35425
distributed.worker - INFO -          dashboard at:           10.32.2.36:37449
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:34993
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:           10.32.2.36:39451
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:43029
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:45993
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:34891
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:34993
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.36:41175
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:32995
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:45993
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:43243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:34891
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.36:32855
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:35733
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-lax6yg78
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:32995
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:           10.32.2.36:36553
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:43243
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:45367
distributed.worker - INFO -          dashboard at:           10.32.2.36:38317
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:35733
distributed.worker - INFO -          dashboard at:           10.32.2.36:37363
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.36:40971
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:45367
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.36:35219
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:34205
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-lq71tmqb
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:35215
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-14zaa7ss
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-von5do41
distributed.worker - INFO -          dashboard at:           10.32.2.36:45149
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:33389
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:38611
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:34205
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:33797
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:35215
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-xofw8j0f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:33389
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:36337
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:33673
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:38611
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:34179
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.36:40877
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:33797
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:           10.32.2.36:44039
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-pr5lddai
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-8_l_cf89
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.36:45701
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:36337
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:40867
distributed.worker - INFO -          dashboard at:           10.32.2.36:44793
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:33673
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-xylz3rgy
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:34179
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:           10.32.2.36:40361
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.36:36877
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:32993
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:44169
distributed.worker - INFO -          dashboard at:           10.32.2.36:34631
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:40867
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:44169
distributed.worker - INFO -          dashboard at:           10.32.2.36:37211
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:41381
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ahx4y3rs
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-1lq_f4x1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:32993
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          dashboard at:           10.32.2.36:44751
distributed.worker - INFO -          dashboard at:           10.32.2.36:40475
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:41381
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-i0o9smlq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.36:45107
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:45849
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-w2kp30_a
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:43375
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -          dashboard at:           10.32.2.36:39503
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:45849
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:43375
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-4_hnkkm6
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-rfb0_3r0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.36:44487
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          dashboard at:           10.32.2.36:38373
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:36077
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-3ys0dx3q
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-jfd4zepv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ul1vkcsz
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-bitdm4r8
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-egt2kn44
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-z2iqwk8c
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ag4799ps
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-9t813zu2
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-pmcs5elj
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-omag55m5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ml6ax165
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-o1dasbc1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:34671
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:34671
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.36:38231
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:43799
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:43799
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-r6k4pznr
distributed.worker - INFO -          dashboard at:           10.32.2.36:46629
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_pog5zoc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:36077
distributed.worker - INFO -          dashboard at:           10.32.2.36:46311
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-q9yp2z5q
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:33975
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:33975
distributed.worker - INFO -          dashboard at:           10.32.2.36:37729
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-oird7b7i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:36845
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:36845
distributed.worker - INFO -          dashboard at:           10.32.2.36:34451
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-bnwyuerc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.36:36269
distributed.worker - INFO -          Listening to:     tcp://10.32.2.36:36269
distributed.worker - INFO -          dashboard at:           10.32.2.36:42537
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-b3_j6m2k
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:42727
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.473098 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f427.root}: entry range [0,61540412], using slot 0 in thread 139706057246464.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.422063 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f372.root}: entry range [0,61540412], using slot 0 in thread 139698383922944.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:738 in void ROOT::Detail::RDF::RLoopManager::Run()>: Starting event loop number 0.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.380645 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f701.root}: entry range [0,61540412], using slot 0 in thread 140465107367680.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.382861 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f702.root}: entry range [0,61540412], using slot 0 in thread 139931200333568.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.381726 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f689.root}: entry range [0,61540412], using slot 0 in thread 140078127486720.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.457218 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f641.root}: entry range [0,61540412], using slot 0 in thread 140036300764928.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.379375 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f679.root}: entry range [0,61540412], using slot 0 in thread 139730929620736.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.427679 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f657.root}: entry range [0,61540412], using slot 0 in thread 139899066435328.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:713 in void ROOT::Detail::RDF::RLoopManager::Jit()>: Just-in-time compilation phase completed in 2.473546 seconds.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:480 in void ROOT::Detail::RDF::RLoopManager::RunTreeReader()>: Processing trees {Events} in files {input_files/dimuon/f672.root}: entry range [0,61540412], using slot 0 in thread 140437131110144.
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.85s CPU, 9.69807s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.21s CPU, 10.1834s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.86s CPU, 9.72462s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.18s CPU, 9.69265s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.74s CPU, 9.21322s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.18s CPU, 9.63635s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (8.98s CPU, 9.54693s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.21s CPU, 10.3514s elapsed).
Info in <[ROOT.RDF] Info /hpcscratch/user/ikabadzh/root/tree/dataframe/src/RLoopManager.cxx:762 in void ROOT::Detail::RDF::RLoopManager::Run()>: Finished event loop number 0 (9.2s CPU, 9.64775s elapsed).
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:32871'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:35577'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:40989'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:44689'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:33673
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:34179
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:46727'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:39457'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:40681'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:43799
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:34475'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:35733
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:42093'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:43375
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:41927'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:36337
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:33797
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:41381
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:38611
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:38765'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:45367
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:39969'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:33109'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:36385'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:34993
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:36345'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:32993
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:33975
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:33389
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:34735'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:39419'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:45849
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:40333'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:41681'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:36845
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:34101'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:43243
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.36:36421'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:34671
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:43029
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:45993
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:32995
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:33673
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:34179
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:43799
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:43375
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f783c57ed00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:35733
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fb011ff2cd0>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f3a93e69d00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:36337
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f8149110cd0>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f55daf38cd0>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:38611
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:33797
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:42727
distributed.worker - INFO - -------------------------------------------------
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f017cc17d00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:32993
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f4db729ed00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fbc20fd0cd0>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:34993
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:33975
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f6c9b50ad30>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:45849
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fbff2e27d00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f0d73a20d00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:43243
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f7e8e540d00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:45993
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fee210c2d00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.36:34671
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f25ab773cd0>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7febf4e06d00>>, <Task finished name='Task-18' coro=<Worker.handle_scheduler() done, defined at /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py:1045> exception=CommClosedError('ConnectionPool not running. Status: Status.closed')>)
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/core.py", line 283, in connect
    comm = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1043, in connect
    comm = await fut
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1058, in handle_scheduler
    await self.close(report=False)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1275, in close
    await r.close_gracefully()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 871, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 1054, in connect
    raise CommClosedError(
distributed.comm.core.CommClosedError: ConnectionPool not running. Status: Status.closed
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 335, in start
    response = await self.instantiate()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 404, in instantiate
    result = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 273, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1128, in __call__
    return self.main(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1053, in main
    rv = self.invoke(ctx)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 754, in invoke
    return __callback(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 691, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 277, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313200 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313195 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313191 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313188 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313183 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313179 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313172 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313170 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313166 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313164 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313160 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313157 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313155 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313152 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313142 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313140 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313136 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313133 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313131 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313128 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313124 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313122 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313119 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313115 parent=313069 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=313109 parent=313069 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
