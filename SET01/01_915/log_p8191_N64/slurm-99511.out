Auks API request failed : krb5 cred : unable to read credential cache
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:32943'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:42281'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:41041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:37191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:46769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:46081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:45597'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:39915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:34617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:41257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:40877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:37629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:39647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:40751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:38047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:41653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:33771'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:42309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:44031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:40027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:35457'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:41507'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:42767'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:45161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:37155'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:43799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:45521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:41767'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:39719'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:42999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:38481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.31:33747'
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:35235
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:34053
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:35235
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:34053
distributed.worker - INFO -          dashboard at:           10.32.2.31:35199
distributed.worker - INFO -          dashboard at:           10.32.2.31:42595
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:37983
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:37983
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:42041
distributed.worker - INFO -          dashboard at:           10.32.2.31:34355
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-h0o7syc5
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:42041
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-7vw0f8ho
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.31:41087
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-g4wutn58
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vmlasidt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:35139
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:35139
distributed.worker - INFO -          dashboard at:           10.32.2.31:35427
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-p_6exn5p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:37817
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:37817
distributed.worker - INFO -          dashboard at:           10.32.2.31:38539
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-qv48fi01
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:45683
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:45683
distributed.worker - INFO -          dashboard at:           10.32.2.31:33995
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-gcndn7ej
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:42945
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:42945
distributed.worker - INFO -          dashboard at:           10.32.2.31:34907
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-753qr82z
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:40955
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:40955
distributed.worker - INFO -          dashboard at:           10.32.2.31:42411
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-w_5j7w2_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:38611
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:38611
distributed.worker - INFO -          dashboard at:           10.32.2.31:33155
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-uk_fjz86
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:33651
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:33651
distributed.worker - INFO -          dashboard at:           10.32.2.31:41657
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-pmag9ln2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:36079
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:36079
distributed.worker - INFO -          dashboard at:           10.32.2.31:44259
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-r057qrw0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:35941
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:35941
distributed.worker - INFO -          dashboard at:           10.32.2.31:37825
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-swam_bkb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:37193
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:37193
distributed.worker - INFO -          dashboard at:           10.32.2.31:42673
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vv8d5_2i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:43209
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:43209
distributed.worker - INFO -          dashboard at:           10.32.2.31:45323
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-61_13n_h
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:33601
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:33601
distributed.worker - INFO -          dashboard at:           10.32.2.31:41793
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-zs96zup0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:39685
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:39685
distributed.worker - INFO -          dashboard at:           10.32.2.31:35533
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-84lm4lfb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:43981
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:43981
distributed.worker - INFO -          dashboard at:           10.32.2.31:36731
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-iwvx4yjz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:45811
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:45811
distributed.worker - INFO -          dashboard at:           10.32.2.31:42353
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-3qpisdoj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:36327
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:36327
distributed.worker - INFO -          dashboard at:           10.32.2.31:34501
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-d0ht9uf2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:42687
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:42687
distributed.worker - INFO -          dashboard at:           10.32.2.31:42093
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-dxizdo73
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:46357
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:46357
distributed.worker - INFO -          dashboard at:           10.32.2.31:33483
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ttv7xntb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:40321
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:40321
distributed.worker - INFO -          dashboard at:           10.32.2.31:43843
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-jk4id50z
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:35509
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:35509
distributed.worker - INFO -          dashboard at:           10.32.2.31:34235
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-eisap_4r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:38477
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:38477
distributed.worker - INFO -          dashboard at:           10.32.2.31:46133
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-wy2vnru1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:43067
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:43067
distributed.worker - INFO -          dashboard at:           10.32.2.31:41143
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-7mw9aouq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:41671
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:41671
distributed.worker - INFO -          dashboard at:           10.32.2.31:41823
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_z3tsxvl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:39039
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:39039
distributed.worker - INFO -          dashboard at:           10.32.2.31:39671
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-f3i5kg52
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:43317
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:43317
distributed.worker - INFO -          dashboard at:           10.32.2.31:37243
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-t8vbz9gq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:37365
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:37365
distributed.worker - INFO -          dashboard at:           10.32.2.31:39181
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-zptirkpp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:39861
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:39861
distributed.worker - INFO -          dashboard at:           10.32.2.31:39325
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-b34bthc5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.31:40541
distributed.worker - INFO -          Listening to:     tcp://10.32.2.31:40541
distributed.worker - INFO -          dashboard at:           10.32.2.31:36379
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-7b_ascck
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:37983
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:34053
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:42041
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:35139
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:35235
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:41041'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:32943'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:42281'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:37191'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:45161'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:45597'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:46081'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:46769'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:40955
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:39915'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:45683
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:34617'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:38611
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:40877'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:41671
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:41257'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:33651
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:37629'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:39685
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:39647'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:40751'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:36327
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:38047'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:46357
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:41653'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:40321
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:33601
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:42945
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:33771'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:43209
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:44031'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:42309'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:40541
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:40027'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:43981
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:35457'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:45811
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:41507'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:43067
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:42767'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:37817
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:37155'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:36079
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:43799'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:45521'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:39039
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:41767'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:43317
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:37365
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:38477
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:39719'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:42999'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:39861
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:33747'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.31:38481'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:35941
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:35509
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:37193
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.31:42687
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 335, in start
    response = await self.instantiate()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 404, in instantiate
    result = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 273, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1128, in __call__
    return self.main(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1053, in main
    rv = self.invoke(ctx)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 754, in invoke
    return __callback(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 691, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 277, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347332 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347327 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347329 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347320 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347305 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347302 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347298 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347295 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347293 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347290 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347284 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347278 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347271 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347269 parent=347207 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=347260 parent=347207 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/process.py", line 234, in _watch_process
Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stderr>'> at interpreter shutdown, possibly due to daemon threads
Python runtime state: finalizing (tstate=0x5582417e7730)

Current thread 0x00007f5657efd740 (most recent call first):
<no Python frame>
/var/spool/slurmd/job99511/slurm_script: line 10: 347207 Aborted                 (core dumped) /hpcscratch/user/ikabadzh/mambaforge/envs/myenv/bin/python3 -m distributed.cli.dask_worker tcp://188.185.68.194:46122 --nthreads 1 --nprocs 32 --memory-limit 14.90GiB --name SLURMCluster-3 --nanny --death-timeout 60 --local-directory /tmp/ikabadzh --protocol tcp://
