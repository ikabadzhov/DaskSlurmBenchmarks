Auks API request failed : krb5 cred : unable to read credential cache
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:34367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:43449'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:41891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:39877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:45801'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:37035'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:41109'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:45431'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:46219'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:39637'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:36221'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:45757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:43439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:33721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:44643'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:34697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:45627'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:43093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:37195'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:37077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:43123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:37311'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:46233'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:38807'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:33069'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:33337'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:41327'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:35367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:43913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:41113'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:42587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.13:34765'
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-e0_jv7d2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/tmp/ikabadzh/dask-worker-space/worker-kinvupva', purging
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:42079
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:42079
distributed.worker - INFO -          dashboard at:           10.32.2.13:35219
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-p2vrjttd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:40733
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:40733
distributed.worker - INFO -          dashboard at:           10.32.2.13:39191
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-40m50juq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:45375
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:45375
distributed.worker - INFO -          dashboard at:           10.32.2.13:40315
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-fxh_109v
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:33743
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:33743
distributed.worker - INFO -          dashboard at:           10.32.2.13:45069
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-g_cviatb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:40705
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:40705
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:33977
distributed.worker - INFO -          dashboard at:           10.32.2.13:33685
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:33977
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO -          dashboard at:           10.32.2.13:42287
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-1ykp5l5e
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-zp7yvy29
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:44551
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:44551
distributed.worker - INFO -          dashboard at:           10.32.2.13:39645
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-t837rhu3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:46009
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:46009
distributed.worker - INFO -          dashboard at:           10.32.2.13:36705
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-uxhh8z1x
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:37843
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:37843
distributed.worker - INFO -          dashboard at:           10.32.2.13:46727
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-corndec_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:41117
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:41117
distributed.worker - INFO -          dashboard at:           10.32.2.13:39275
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-od01xy1i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:36041
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:36041
distributed.worker - INFO -          dashboard at:           10.32.2.13:45367
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-t2a3mou7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:45933
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:45933
distributed.worker - INFO -          dashboard at:           10.32.2.13:35455
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-bk9eq0ia
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:34191
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:34191
distributed.worker - INFO -          dashboard at:           10.32.2.13:44365
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-58sofu3m
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:44025
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:44025
distributed.worker - INFO -          dashboard at:           10.32.2.13:35111
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-9zft2i00
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:39579
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:39579
distributed.worker - INFO -          dashboard at:           10.32.2.13:45583
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:38949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:38949
distributed.worker - INFO -          dashboard at:           10.32.2.13:45161
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-gt43e1q8
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ogxjxii6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:44525
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:44525
distributed.worker - INFO -          dashboard at:           10.32.2.13:37509
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_2xe3dvz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:43833
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:43833
distributed.worker - INFO -          dashboard at:           10.32.2.13:46867
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vm2ic2n6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:45667
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:45667
distributed.worker - INFO -          dashboard at:           10.32.2.13:41767
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-rr0esxa2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:36853
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:36853
distributed.worker - INFO -          dashboard at:           10.32.2.13:42207
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_svtvjgj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:34001
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:34001
distributed.worker - INFO -          dashboard at:           10.32.2.13:43193
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-o59pyhq_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:38789
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:38789
distributed.worker - INFO -          dashboard at:           10.32.2.13:38179
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-raame8n8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:46751
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:46751
distributed.worker - INFO -          dashboard at:           10.32.2.13:35613
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_nvqdt8_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:35077
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:35077
distributed.worker - INFO -          dashboard at:           10.32.2.13:34957
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-hpe58sc6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:43917
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:43917
distributed.worker - INFO -          dashboard at:           10.32.2.13:33135
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-269ltirt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:43425
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:43425
distributed.worker - INFO -          dashboard at:           10.32.2.13:45803
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-uupp4oyf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:40903
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:40903
distributed.worker - INFO -          dashboard at:           10.32.2.13:36905
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-20gcxerr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:38079
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:38079
distributed.worker - INFO -          dashboard at:           10.32.2.13:46695
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-i5dgfp42
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:33861
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:33861
distributed.worker - INFO -          dashboard at:           10.32.2.13:39251
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-_isp3h5n
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:39061
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:39061
distributed.worker - INFO -          dashboard at:           10.32.2.13:36411
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ywd1d30w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:40713
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.13:40561
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:40713
distributed.worker - INFO -          Listening to:     tcp://10.32.2.13:40561
distributed.worker - INFO -          dashboard at:           10.32.2.13:39507
distributed.worker - INFO -          dashboard at:           10.32.2.13:34597
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-buc3196d
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-zkp666xj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 198, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1001, in heartbeat
    response = await retry_operation(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 385, in retry_operation
    return await retry(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 370, in retry
    return await coro()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 874, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 651, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.32.2.13:60322 remote=tcp://188.185.68.194:46122>: Stream is closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1001, in heartbeat
    response = await retry_operation(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 385, in retry_operation
    return await retry(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 370, in retry
    return await coro()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 874, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 651, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 126, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.32.2.13:60330 remote=tcp://188.185.68.194:46122>: ConnectionResetError: [Errno 104] Connection reset by peer
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:37843
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:38789
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:45757'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:37311'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:36041
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:41891'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:39579
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:34191
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:38949
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:44025
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:42587'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:45431'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:44525
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:43833
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:43439'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:41109'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:45667
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:35367'
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:46751
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:36221'
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:35077
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:36853
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:34765'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:43913'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:34697'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:44643'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:40733
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:43917
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:33977
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:40705
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:33337'
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:45375
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:33743
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:43123'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:45801'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:43449'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:39877'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:41327'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:46009
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:44551
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:34367'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:46233'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:40903
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:33069'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:38079
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:33861
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:39061
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:40713
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:40561
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:41113'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:33721'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:37195'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:37077'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:45627'
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:42079
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:37035'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:43093'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:38807'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:34001
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:43425
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.13:41117
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.13:46219'
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 335, in start
    response = await self.instantiate()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 404, in instantiate
    result = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 273, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1128, in __call__
    return self.main(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1053, in main
    rv = self.invoke(ctx)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 754, in invoke
    return __callback(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 691, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 277, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=312703 parent=312638 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
