Auks API request failed : krb5 cred : unable to read credential cache
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:36853'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:46543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:35611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:39775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:36891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:39411'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:43971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:44513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:37271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:44499'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:39537'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:43715'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:39573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:37643'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:39661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:45631'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:43423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:37299'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:42351'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:32945'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:37621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:38397'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:46413'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:38077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:39143'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:38307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:41153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:37943'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:36661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:44005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:34599'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.32.2.39:46321'
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:45793
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:45793
distributed.worker - INFO -          dashboard at:           10.32.2.39:40489
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-8zjle_ku
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:39293
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:39293
distributed.worker - INFO -          dashboard at:           10.32.2.39:40241
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-s_6acgje
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:40287
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:40287
distributed.worker - INFO -          dashboard at:           10.32.2.39:46523
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-5hz65d97
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:37901
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:37901
distributed.worker - INFO -          dashboard at:           10.32.2.39:44571
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-xkaorfae
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:38035
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:38035
distributed.worker - INFO -          dashboard at:           10.32.2.39:35333
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-jssfcuaz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:45633
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:45633
distributed.worker - INFO -          dashboard at:           10.32.2.39:34571
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-en6lx04a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:36941
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:36941
distributed.worker - INFO -          dashboard at:           10.32.2.39:32829
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-hl8ux1ak
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:45649
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:45649
distributed.worker - INFO -          dashboard at:           10.32.2.39:40189
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-faggvoar
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:36607
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:36607
distributed.worker - INFO -          dashboard at:           10.32.2.39:39373
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-3wjam43r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:37819
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:37819
distributed.worker - INFO -          dashboard at:           10.32.2.39:38915
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-zpwjlhbe
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:35141
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:35141
distributed.worker - INFO -          dashboard at:           10.32.2.39:43593
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-fy1nu5tv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:39867
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:39867
distributed.worker - INFO -          dashboard at:           10.32.2.39:36561
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-esf8a3cu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:37545
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:37545
distributed.worker - INFO -          dashboard at:           10.32.2.39:40297
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-xcjkzjzd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:38563
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:38563
distributed.worker - INFO -          dashboard at:           10.32.2.39:44989
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-2ua7xqms
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:41015
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:41015
distributed.worker - INFO -          dashboard at:           10.32.2.39:35129
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-l8a3rhmx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:39005
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:39005
distributed.worker - INFO -          dashboard at:           10.32.2.39:38543
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-7rt3gjsd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:41569
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:41569
distributed.worker - INFO -          dashboard at:           10.32.2.39:42129
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-faby6r0l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:41767
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:41767
distributed.worker - INFO -          dashboard at:           10.32.2.39:43351
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ae87e1zi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:43717
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:43717
distributed.worker - INFO -          dashboard at:           10.32.2.39:37359
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-ghuy0pem
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:38251
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:38251
distributed.worker - INFO -          dashboard at:           10.32.2.39:44697
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-fbkquxrd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:41955
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:41955
distributed.worker - INFO -          dashboard at:           10.32.2.39:35545
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-vf7i4qb1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:45101
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:45101
distributed.worker - INFO -          dashboard at:           10.32.2.39:37969
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-o0hizrmi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:45307
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:45307
distributed.worker - INFO -          dashboard at:           10.32.2.39:34785
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-18c_upx2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:36377
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:36377
distributed.worker - INFO -          dashboard at:           10.32.2.39:35269
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-n0jg_n2p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:42653
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:35637
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:35637
distributed.worker - INFO -          dashboard at:           10.32.2.39:39827
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:42653
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.32.2.39:35117
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-50njlfl3
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-wusq9ymw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:43151
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:43151
distributed.worker - INFO -          dashboard at:           10.32.2.39:36289
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-1jha_jfd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:44293
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:44293
distributed.worker - INFO -          dashboard at:           10.32.2.39:41091
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-4adkjgcz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:38623
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:38623
distributed.worker - INFO -          dashboard at:           10.32.2.39:40899
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-kz26wwa_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:34025
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:34025
distributed.worker - INFO -          dashboard at:           10.32.2.39:35999
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-28ir0t1p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:43459
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:43459
distributed.worker - INFO -          dashboard at:           10.32.2.39:36027
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-onw_ngmj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.32.2.39:38973
distributed.worker - INFO -          Listening to:     tcp://10.32.2.39:38973
distributed.worker - INFO -          dashboard at:           10.32.2.39:41451
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                  14.90 GiB
distributed.worker - INFO -       Local Directory: /tmp/ikabadzh/dask-worker-space/worker-dz573acb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 198, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1001, in heartbeat
    response = await retry_operation(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 385, in retry_operation
    return await retry(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 370, in retry
    return await coro()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 874, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 651, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.32.2.39:51982 remote=tcp://188.185.68.194:46122>: Stream is closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 198, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1001, in heartbeat
    response = await retry_operation(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 385, in retry_operation
    return await retry(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 370, in retry
    return await coro()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 874, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 651, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.32.2.39:51984 remote=tcp://188.185.68.194:46122>: Stream is closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 198, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/worker.py", line 1001, in heartbeat
    response = await retry_operation(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 385, in retry_operation
    return await retry(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/utils_comm.py", line 370, in retry
    return await coro()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 874, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 651, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 214, in read
    convert_stream_closed_error(self, e)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.32.2.39:51986 remote=tcp://188.185.68.194:46122>: Stream is closed
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Waiting to connect to: tcp://188.185.68.194:46122
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:45793
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:40287
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:36853'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:35611'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:39293
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:46543'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:46321'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:32945'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:34599'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:37901
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:44005'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:36661'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:43459
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:37943'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:41015
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:38973
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:39005
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:39661'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:43715'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:41767
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:41153'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:42653
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:39143'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:43151
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:38077'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:44293
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:46413'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:41955
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:43423'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:38397'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:41569
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:38251
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:44499'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:42351'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:38035
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:39867
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:38307'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:45631'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:36607
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:45307
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:37299'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:38623
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:37643'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:45649
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:39573'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:45101
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:37621'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:36377
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:39537'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:45633
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:43717
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:39411'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:39775'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:38563
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:36891'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:37271'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:34025
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:35141
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:44513'
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:36941
distributed.nanny - INFO - Closing Nanny at 'tcp://10.32.2.39:43971'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:37819
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:35637
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://10.32.2.39:37545
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 335, in start
    response = await self.instantiate()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/nanny.py", line 404, in instantiate
    result = await asyncio.wait_for(
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 468, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 492, in wait_for
    fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 273, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 494, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1128, in __call__
    return self.main(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1053, in main
    rv = self.invoke(ctx)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 1395, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/click/core.py", line 754, in invoke
    return __callback(*args, **kwargs)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/asyncio/tasks.py", line 691, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/site-packages/distributed/core.py", line 277, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366183 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366167 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366149 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366147 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366143 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366137 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366135 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366129 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366126 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366122 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366116 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366113 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366107 parent=366055 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=366101 parent=366055 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/hpcscratch/user/ikabadzh/mambaforge/envs/myenv/lib/python3.9/threading.py", line 973, in _bootstrap_inner
